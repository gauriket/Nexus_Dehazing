{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-27T09:34:02.382800Z","iopub.execute_input":"2023-10-27T09:34:02.383217Z","iopub.status.idle":"2023-10-27T09:34:02.864148Z","shell.execute_reply.started":"2023-10-27T09:34:02.383179Z","shell.execute_reply":"2023-10-27T09:34:02.862942Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hazetestvideo/hazevideo1.mp4\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom os.path import isfile\n\ndef video2framesarray(videoinput):\n    cap = cv2.VideoCapture(videoinput)\n    frame_number = 0\n    frame_array = []\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_array.append(frame)\n        frame_number += 1\n    cap.release()\n    return frame_array","metadata":{"execution":{"iopub.status.busy":"2023-10-27T09:37:49.314839Z","iopub.execute_input":"2023-10-27T09:37:49.315245Z","iopub.status.idle":"2023-10-27T09:37:49.322365Z","shell.execute_reply.started":"2023-10-27T09:37:49.315216Z","shell.execute_reply":"2023-10-27T09:37:49.321407Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def atmosdehaze(frame):\n    # Convert the image to floating point representation\n    hazy_image = frame.astype(np.float32) / 255.0\n\n    # Estimate the atmospheric light\n    dark_channel = np.min(hazy_image, axis=2)\n    atmospheric_light = np.percentile(dark_channel, 99)\n\n    # Estimate the transmission map\n    transmission = 1 - 0.95 * dark_channel / (atmospheric_light + 1e-6)  # Add a small epsilon value\n\n    # Clamp the transmission values to [0, 1]\n    transmission = np.clip(transmission, 0, 1)\n\n    # Estimate the scene radiance\n    scene_radiance = np.zeros_like(hazy_image)\n    for channel in range(3):\n        scene_radiance[:, :, channel] = (hazy_image[:, :, channel] - atmospheric_light) / (transmission + 1e-6) + atmospheric_light  # Add a small epsilon value\n\n    # Clamp the scene radiance values to [0, 1]\n    scene_radiance = np.clip(scene_radiance, 0, 1)\n\n    # Convert the scene radiance back to 8-bit representation\n    scene_radiance = (scene_radiance * 255).astype(np.uint8)\n    return scene_radiance\n\ndef dehaze_images(frame_array):\n    dehazed_frames = []\n    for frame in frame_array:\n        dehazed_frame = atmosdehaze(frame)\n        dehazed_frames.append(dehazed_frame)\n\n    # Convert the dehazed frames to an array\n    dehazed_array = np.array(dehazed_frames)\n    return dehazed_array","metadata":{"execution":{"iopub.status.busy":"2023-10-27T09:37:56.055019Z","iopub.execute_input":"2023-10-27T09:37:56.055450Z","iopub.status.idle":"2023-10-27T09:37:56.065986Z","shell.execute_reply.started":"2023-10-27T09:37:56.055418Z","shell.execute_reply":"2023-10-27T09:37:56.064582Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def dehazed2video(dehazed_array, pathOut, fps=30):\n    size = (dehazed_array[0].shape[1], dehazed_array[0].shape[0])\n    out = cv2.VideoWriter(pathOut, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n    for i in range(len(dehazed_array)):\n        out.write(dehazed_array[i])\n    out.release()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T09:38:05.355274Z","iopub.execute_input":"2023-10-27T09:38:05.355703Z","iopub.status.idle":"2023-10-27T09:38:05.363115Z","shell.execute_reply.started":"2023-10-27T09:38:05.355668Z","shell.execute_reply":"2023-10-27T09:38:05.361786Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def main(input_video, output_video):\n    frame_array = video2framesarray(input_video)\n    dehazed_array = dehaze_images(frame_array)\n    dehazed2video(dehazed_array, output_video)\n\nif __name__ == '__main__':\n    input_video = '/kaggle/input/hazetestvideo/hazevideo1.mp4'\n    output_video = 'output_video.avi'  # Change the format as needed\n    main(input_video, output_video)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T09:38:11.355407Z","iopub.execute_input":"2023-10-27T09:38:11.355872Z","iopub.status.idle":"2023-10-27T09:38:32.893798Z","shell.execute_reply.started":"2023-10-27T09:38:11.355839Z","shell.execute_reply":"2023-10-27T09:38:32.892857Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nimport cv2\nimport numpy as np\n\napp = Flask(__name__)\n\ndef atmosdehaze(frame):\n    # Convert the image to floating point representation\n    hazy_image = frame.astype(np.float32) / 255.0\n\n    # Estimate the atmospheric light\n    dark_channel = np.min(hazy_image, axis=2)\n    atmospheric_light = np.percentile(dark_channel, 99)\n\n    # Estimate the transmission map\n    transmission = 1 - 0.95 * dark_channel / (atmospheric_light + 1e-6)  # Add a small epsilon value\n\n    # Clamp the transmission values to [0, 1]\n    transmission = np.clip(transmission, 0, 1)\n\n    # Estimate the scene radiance\n    scene_radiance = np.zeros_like(hazy_image)\n    for channel in range(3):\n        scene_radiance[:, :, channel] = (hazy_image[:, :, channel] - atmospheric_light) / (transmission + 1e-6) + atmospheric_light  # Add a small epsilon value\n\n    # Clamp the scene radiance values to [0, 1]\n    scene_radiance = np.clip(scene_radiance, 0, 1)\n\n    # Convert the scene radiance back to 8-bit representation\n    scene_radiance = (scene_radiance * 255).astype(np.uint8)\n    return scene_radiance\n\n# Define the API endpoint for dehazing a video\n@app.route('/dehaze', methods=['POST'])\ndef dehaze_video():\n    # Check if the request contains a file\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file uploaded'})\n\n    file = request.files['file']\n\n    # Check if the file is a video\n    if file.filename == '':\n        return jsonify({'error': 'No file selected'})\n\n    if file and allowed_file(file.filename):\n        # Save the video file\n        video_path = 'input_video.mp4'\n        file.save(video_path)\n\n        # Process the video\n        frame_array = video2framesarray(video_path)\n        dehazed_array = dehaze_images(frame_array)\n\n        # Save the dehazed video\n        output_video_path = 'output_video.avi'\n        dehazed2video(dehazed_array, output_video_path)\n\n        return jsonify({'message': 'Video dehazed successfully'})\n\n    return jsonify({'error': 'Invalid file format'})\n\nif __name__ == '__main__':\n    app.run()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastapi import FastAPI, UploadFile, File, Form\nfrom fastapi.responses import FileResponse\nimport shutil\nimport cv2\nimport numpy as np\nimport os\nimport asyncio\n\napp = FastAPI()\n\ndef video2framesarray(videoinput):\n    cap = cv2.VideoCapture(videoinput)\n    frame_number = 0\n    frame_array = []\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_array.append(frame)\n        frame_number += 1\n    cap.release()\n    return frame_array\n\ndef atmosdehaze(frame):\n    # Convert the image to floating point representation\n    hazy_image = frame.astype(np.float32) / 255.0\n\n    # Estimate the atmospheric light\n    dark_channel = np.min(hazy_image, axis=2)\n    atmospheric_light = np.percentile(dark_channel, 99)\n\n    # Estimate the transmission map\n    transmission = 1 - 0.95 * dark_channel / (atmospheric_light + 1e-6)  # Add a small epsilon value\n\n    # Clamp the transmission values to [0, 1]\n    transmission = np.clip(transmission, 0, 1)\n\n    # Estimate the scene radiance\n    scene_radiance = np.zeros_like(hazy_image)\n    for channel in range(3):\n        scene_radiance[:, :, channel] = (hazy_image[:, :, channel] - atmospheric_light) / (transmission + 1e-6) + atmospheric_light  # Add a small epsilon value\n\n    # Clamp the scene radiance values to [0, 1]\n    scene_radiance = np.clip(scene_radiance, 0, 1)\n\n    # Convert the scene radiance back to 8-bit representation\n    scene_radiance = (scene_radiance * 255).astype(np.uint8)\n    return scene_radiance\n\ndef dehaze_images(frame_array):\n    dehazed_frames = []\n    for frame in frame_array:\n        dehazed_frame = atmosdehaze(frame)\n        dehazed_frames.append(dehazed_frame)\n\n    # Convert the dehazed frames to an array\n    dehazed_array = np.array(dehazed_frames)\n    return dehazed_array\n\ndef dehazed2video(dehazed_array, pathOut, fps=30):\n    size = (dehazed_array[0].shape[1], dehazed_array[0].shape[0])\n    out = cv2.VideoWriter(pathOut, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n    for i in range(len(dehazed_array)):\n        out.write(dehazed_array[i])\n    out.release()\n\ndef dehaze_video(input_path, output_path):\n    frame_array = video2framesarray(input_path)\n    dehazed_array = dehaze_images(frame_array)\n    dehazed2video(dehazed_array, output_path)\n\n@app.post(\"/dehaze\")\nasync def dehaze_endpoint(file: UploadFile = File(...), fps: int = Form(...)):\n    if file.content_type != \"video/mp4\":\n        return {\"error\": \"Only MP4 videos are supported.\"}\n\n    input_video = \"temp_video.mp4\"\n    output_video = \"output_video.mp4\"  # You can change the format as needed\n\n    with open(input_video, \"wb\") as f:\n        shutil.copyfileobj(file.file, f)\n\n    await asyncio.to_thread(dehaze_video, input_video, output_video)\n\n    return FileResponse(output_video, media_type=\"video/mp4\")\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\ndef preprocess_image(image, model_input_shape):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Ensure RGB format\n    image = cv2.resize(image, (model_input_shape[2], model_input_shape[1]))  # Resize to match the model's input shape\n    image = image / 255.0  # Normalize pixel values to the range [0, 1]\n    return image\n\n# Define the post-processing function for dehazing\ndef postprocess_image(image):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    image = (image * 255).astype(np.uint8)\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-10-27T09:34:03.164564Z","iopub.execute_input":"2023-10-27T09:34:03.164909Z","iopub.status.idle":"2023-10-27T09:34:03.172835Z","shell.execute_reply.started":"2023-10-27T09:34:03.164879Z","shell.execute_reply":"2023-10-27T09:34:03.171488Z"},"trusted":true},"execution_count":3,"outputs":[]}]}